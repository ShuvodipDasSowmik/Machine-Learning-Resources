{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction To Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A tensor is a mathematical object that generalizes scalars, vectors, and matrices to higher dimensions. In simple terms, a tensor is an n-dimensional array or a multi-dimensional matrix used to represent data in machine learning, deep learning, and scientific computing.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Scalar (0-D Tensor):*\n",
    "\n",
    "`A single number.`\n",
    "`Example:` 5.0, 42, -3\n",
    "\n",
    "*Vector (1-D Tensor):*\n",
    "\n",
    "`A one-dimensional array of numbers.`\n",
    "`Example:` [1, 2, 3], [0.1, 0.2, 0.3]\n",
    "\n",
    "*Matrix (2-D Tensor):*\n",
    "\n",
    "`A two-dimensional array (rows and columns).`\n",
    "`Example:`\n",
    "\n",
    "[[1, 2],\n",
    "[3, 4]]\n",
    "\n",
    "*Higher-dimensional Tensors (n-D Tensors):*\n",
    "\n",
    "`Tensors with 3 or more dimensions, used in deep learning and more complex data representations.`\n",
    "`Example (3D tensor): A batch of 2 images, each of 3x4 pixels with RGB channels`\n",
    "\n",
    "*[[[r1, g1, b1], [r2, g2, b2], [r3, g3, b3], [r4, g4, b4]],\n",
    " [[r5, g5, b5], [r6, g6, b6], [r7, g7, b7], [r8, g8, b8]]]*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCALAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Dimension of a scalar is 0*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 1, 3, 2])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([4, 1, 3, 2])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "print(vector.ndim)\n",
    "print(vector.shape)\n",
    "print(vector.size())\n",
    "#Size and Shape are different version of the same thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 2],\n",
       "        [3, 3, 1],\n",
       "        [5, 3, 2]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1, 3, 2], [3, 3, 1], [5, 3, 2]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "tensor([1, 3, 2])\n",
      "tensor([3, 3, 1])\n",
      "tensor([5, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(matrix.ndim)\n",
    "print(matrix.shape)\n",
    "print(matrix.size())\n",
    "for i in matrix:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "2\n",
      "torch.Size([3, 3])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(tensor)\n",
    "print(tensor.ndim)\n",
    "print(tensor.shape)\n",
    "print(tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "3\n",
      "torch.Size([1, 3, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "print(tensor)\n",
    "print(tensor.ndim)\n",
    "print(tensor.shape)\n",
    "print(tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1, 2, 3],\n",
      "          [4, 5, 6],\n",
      "          [7, 8, 9]]]])\n",
      "4\n",
      "torch.Size([1, 1, 3, 3])\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[[[1, 2, 3], [4, 5, 6], [7, 8, 9]]]])\n",
    "print(tensor)\n",
    "print(tensor.ndim)\n",
    "print(tensor.shape)\n",
    "print(tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1, 2, 3],\n",
      "          [4, 5, 6],\n",
      "          [7, 8, 9]],\n",
      "\n",
      "         [[1, 2, 3],\n",
      "          [4, 5, 6],\n",
      "          [7, 8, 9]]]])\n",
      "4\n",
      "torch.Size([1, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "longerTensor = torch.tensor([[[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]]])\n",
    "print(longerTensor)\n",
    "print(longerTensor.ndim)\n",
    "print(longerTensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Tensors in PyTorch\n",
    "\n",
    "`In PyTorch, random tensors are tensors filled with random values.`\n",
    "\n",
    "`Practical Use Cases for Random Tensors`\n",
    "\n",
    "`Many neural networks learn by starting with full of random numbers and then adjust those random numbers to better represent the data`\n",
    "\n",
    "`Start with Random Numbers -> Look At Data -> Update Random Numbers -> Look At Data -> Update Random Numbers -> ...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3312, 0.0752, 0.3149, 0.6542],\n",
       "         [0.6939, 0.1515, 0.0265, 0.8937],\n",
       "         [0.7700, 0.5684, 0.2044, 0.6173]],\n",
       "\n",
       "        [[0.7816, 0.3948, 0.1487, 0.0305],\n",
       "         [0.0695, 0.4194, 0.7581, 0.0148],\n",
       "         [0.8432, 0.8567, 0.3361, 0.8295]]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Random Tensor of size 2x3x4\n",
    "randomTensor = torch.rand(2, 3, 4)\n",
    "randomTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Any Data can be written as Tensors.`\n",
    "\n",
    "`For example an image of 256x256 resolution will have a tensor of [3, 256, 256] size in RGB color channels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6067, 0.0517, 0.8803,  ..., 0.0791, 0.3062, 0.9022],\n",
       "         [0.1285, 0.1336, 0.9994,  ..., 0.3022, 0.6162, 0.8821],\n",
       "         [0.9649, 0.6898, 0.9435,  ..., 0.9102, 0.8853, 0.0873],\n",
       "         ...,\n",
       "         [0.9492, 0.4058, 0.4100,  ..., 0.1793, 0.5575, 0.8032],\n",
       "         [0.3533, 0.3713, 0.5042,  ..., 0.4452, 0.1972, 0.3207],\n",
       "         [0.9569, 0.7967, 0.7882,  ..., 0.6855, 0.2490, 0.8941]],\n",
       "\n",
       "        [[0.0985, 0.0263, 0.1336,  ..., 0.2715, 0.4140, 0.9128],\n",
       "         [0.4862, 0.0247, 0.9674,  ..., 0.2547, 0.1478, 0.2932],\n",
       "         [0.1959, 0.8216, 0.6547,  ..., 0.5267, 0.4169, 0.1866],\n",
       "         ...,\n",
       "         [0.4436, 0.2666, 0.9630,  ..., 0.0274, 0.6244, 0.0792],\n",
       "         [0.3397, 0.5430, 0.4454,  ..., 0.6859, 0.1008, 0.0789],\n",
       "         [0.7304, 0.1514, 0.2206,  ..., 0.7399, 0.9886, 0.8150]],\n",
       "\n",
       "        [[0.5399, 0.7644, 0.7460,  ..., 0.3654, 0.8150, 0.6719],\n",
       "         [0.1575, 0.2952, 0.4967,  ..., 0.9371, 0.8906, 0.4719],\n",
       "         [0.1857, 0.0155, 0.1253,  ..., 0.6926, 0.5427, 0.7093],\n",
       "         ...,\n",
       "         [0.5769, 0.5941, 0.8197,  ..., 0.1863, 0.7402, 0.4504],\n",
       "         [0.3383, 0.8028, 0.4005,  ..., 0.0595, 0.5852, 0.0272],\n",
       "         [0.3566, 0.7876, 0.7889,  ..., 0.7517, 0.1072, 0.4152]]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomImgSizeTensor = torch.rand(size = (3, 256, 256))\n",
    "randomImgSizeTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor of all zeroes\n",
    "tensorOfZeroes = torch.zeros(3, 3)\n",
    "tensorOfZeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor of all ones\n",
    "tensorOfOnes = torch.ones(3, 3)\n",
    "tensorOfOnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tensors use 32-bit float as its default datatype`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorOfOnes.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Creating Range of Tensors and Tensors-like`\n",
    "\n",
    "`torch.arange(start, end, step) -> stores values from start to (end-1)`\n",
    "\n",
    "`Tensors-like -> Creates a new tensor of the same shape.`\n",
    "\n",
    "`torch.zeros_like(x)`\n",
    "\n",
    "`torch.ones_like(x)`\n",
    "\n",
    "`torch.rand_like(x)`\n",
    "\n",
    "`torch.randn_like(x)`\n",
    "\n",
    "`torch.full_like(x, value)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  2,  4,  6,  8, 10])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneToTen = torch.arange(start = 0, end = 12, step = 2)\n",
    "# or oneToTen = torch.arange(0, 12, 2)\n",
    "oneToTen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creatinng tensors-like\n",
    "tenZeros = torch.zeros_like(oneToTen)\n",
    "tenZeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TENSOR DATA TYPES\n",
    "\n",
    "Tensors have float_32 [torch.float32] set as default datatype\n",
    "\n",
    "use float_64 [torch.float64 / torch.double] for higher precision\n",
    "use float_16 [torch.float16 / torch.half] for half precision\n",
    "\n",
    "3 most common error with Tensors in Pytorch and Deep Learning:\n",
    "1) Tensor is not the right data type\n",
    "2) Tensor is not the right shape\n",
    "3) Tensor not on the right device\n",
    "\n",
    "In PyTorch, tensors can be stored on different devices, such as:\n",
    "\n",
    "CPU (default)\n",
    "GPU (CUDA)\n",
    "\n",
    "requires_grad – Enabling Autograd\n",
    "\n",
    "PyTorch has an automatic differentiation engine called Autograd.\n",
    "If requires_grad=True, PyTorch tracks operations on the tensor, allowing gradient computation.\n",
    "Used for backpropagation in deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32Tensor = torch.tensor([1, 2, 3], \n",
    "                            dtype = None,           #specify data type\n",
    "                            device = \"cpu\",         #\"cuda\" for GPU\n",
    "                            requires_grad = False)  #Whether or not to track the gradient for this tensor's operation\n",
    "float32Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PyTorch's device parameter is essential for controlling where tensors are stored and computations are performed. Since modern hardware includes both CPU and GPU, specifying the device ensures efficient use of available resources.`\n",
    "\n",
    "`CPU (Central Processing Unit): General-purpose, good for small computations but slower for deep learning.`\n",
    "`GPU (Graphics Processing Unit): Optimized for parallel computations, significantly faster for matrix operations (used in deep learning).`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], dtype=torch.float16)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conversion of Tensor data types\n",
    "\n",
    "float16Tensor = float32Tensor.type(torch.float16)\n",
    "float16Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TENSON OPERATIONS\n",
    "\n",
    "- Addition\n",
    "- Subtraction\n",
    "- Multiplication [element-wise]\n",
    "- Division\n",
    "- Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 13, 15])\n",
      "tensor([-9, -7, -5])\n",
      "tensor([10, 30, 50])\n",
      "tensor([0.1000, 0.3000, 0.5000])\n",
      "tensor([11, 13, 15])\n",
      "tensor([-9, -7, -5])\n",
      "tensor([10, 30, 50])\n",
      "tensor([0.1000, 0.3000, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "#Scalar operations\n",
    "\n",
    "x = torch.tensor([1, 3, 5])\n",
    "print(x + 10)\n",
    "print(x - 10)\n",
    "print(x * 10)\n",
    "print(x / 10)\n",
    "\n",
    "print(torch.add(x, 10))\n",
    "print(torch.sub(x, 10))\n",
    "print(torch.mul(x, 10))\n",
    "print(torch.div(x, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3,  7, 11])\n",
      "tensor([-1, -1, -1])\n",
      "tensor([ 2, 12, 30])\n",
      "tensor([0.5000, 0.7500, 0.8333])\n"
     ]
    }
   ],
   "source": [
    "#Operations among tensors\n",
    "\n",
    "y = torch.tensor([2, 4, 6])\n",
    "print(x + y)\n",
    "print(x - y)\n",
    "\n",
    "#Element-wise multiplication\n",
    "print(x * y)\n",
    "\n",
    "print(x / y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 30,  24,  18],\n",
       "        [ 84,  69,  54],\n",
       "        [138, 114,  90]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix Multiplication\n",
    "\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "b = torch.tensor([[9, 8, 7], [6, 5, 4], [3, 2, 1]])\n",
    "\n",
    "torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 30,  24,  18],\n",
       "        [ 84,  69,  54],\n",
       "        [138, 114,  90]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(a, b) #Short form of matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpose of a Tensor\n",
    "\n",
    "In matrix multiplication the number of columns of first Matrix must be equal to the number of rows of second matrix.\n",
    "For example: 3 x 2 and 3 x 2 matrices can't be multiplied.\n",
    "\n",
    "Again for any Matrix 'A', A and Transpose(A) can alway be multiplied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([[1, 4, 7],\n",
      "        [2, 5, 8],\n",
      "        [3, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "newTensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(newTensor)\n",
    "print(newTensor.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding Min, Max, Mean, Sum etc of A Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0606, 0.0411, 0.9788, 0.2781, 0.1825, 0.9915, 0.4756, 0.1290, 0.4479,\n",
       "         0.4566]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0411), tensor(0.0411), tensor(1))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.min(), torch.min(x), torch.argmin(x) #argmin returns the index of the minimum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9915), tensor(0.9915), tensor(5))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.max(), torch.max(x), torch.argmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4042), tensor(0.4042))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.mean() works only on float data type tensors\n",
    "\n",
    "torch.mean(x), x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.0416), tensor(4.0416))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum(), torch.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESHAPING TENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), torch.Size([10]))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "x, x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  2],\n",
       "         [ 3,  4],\n",
       "         [ 5,  6],\n",
       "         [ 7,  8],\n",
       "         [ 9, 10]]),\n",
       " tensor([[ 1,  2,  3,  4,  5],\n",
       "         [ 6,  7,  8,  9, 10]]),\n",
       " tensor([[[ 1,  2],\n",
       "          [ 3,  4],\n",
       "          [ 5,  6],\n",
       "          [ 7,  8],\n",
       "          [ 9, 10]]]))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshapedX = x.reshape(5, 2)\n",
    "reshaedX2 = x.reshape(2, 5)\n",
    "reshaedX3 = x.reshape(1, 5, 2)  # The product of the dimensions of new shape must equal to the number of elements in original tensor\n",
    "reshapedX, reshaedX2, reshaedX3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIEW OF A TENSOR\n",
    "\n",
    "View of a tensor shares the same memory as the original's. Any change to the view will also reflect on the original tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2,  2,  3,  4,  5],\n",
       "         [ 6,  7,  8,  9, 10]]),\n",
       " tensor([-2,  2,  3,  4,  5,  6,  7,  8,  9, 10]))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(2, 5)\n",
    "z[0][0] = -2    #Changes in z will reflect in x\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[100,   2,   3,   4,   5],\n",
       "         [  6,   7,   8,   9,  10]]),\n",
       " tensor([-2,  2,  3,  4,  5,  6,  7,  8,  9, 10]))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(2, 5).clone()\n",
    "z[0][0] = 100    #Changes in z will not reflect in x\n",
    "z, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKING\n",
    "\n",
    "In PyTorch, stacking refers to combining multiple tensors along a new dimension.\n",
    "\n",
    "dim=0 inserts a new first dimension, treating each tensor as a row.\n",
    "dim=1 inserts a new second dimension, treating each tensor as a column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]),\n",
       " tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " tensor([[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "c = torch.tensor([7, 8, 9])\n",
    "\n",
    "stackedTensor = torch.stack((a, b, c), dim = 0)\n",
    "horizontalStack = torch.hstack((a, b, c))\n",
    "verticalStack = torch.vstack((a, b, c))\n",
    "stackedTensor, horizontalStack, verticalStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.1732, 0.1936, 0.1672, 0.3273],\n",
       "          [0.9236, 0.6194, 0.6882, 0.7438]]]),\n",
       " tensor([[[0.2291, 0.9694, 0.8220, 0.7518],\n",
       "          [0.1917, 0.9843, 0.6805, 0.3522]]]),\n",
       " tensor([[[0.3493, 0.5354, 0.3456, 0.4287],\n",
       "          [0.1974, 0.5514, 0.6252, 0.1514]]]),\n",
       " tensor([[[[0.1732, 0.1936, 0.1672, 0.3273],\n",
       "           [0.9236, 0.6194, 0.6882, 0.7438]]],\n",
       " \n",
       " \n",
       "         [[[0.2291, 0.9694, 0.8220, 0.7518],\n",
       "           [0.1917, 0.9843, 0.6805, 0.3522]]],\n",
       " \n",
       " \n",
       "         [[[0.3493, 0.5354, 0.3456, 0.4287],\n",
       "           [0.1974, 0.5514, 0.6252, 0.1514]]]]),\n",
       " torch.Size([1, 2, 4]),\n",
       " torch.Size([3, 1, 2, 4]),\n",
       " torch.Size([1, 3, 2, 4]),\n",
       " torch.Size([1, 2, 3, 4]),\n",
       " torch.Size([1, 2, 4, 3]))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(1, 2, 4)\n",
    "b = torch.rand(1, 2, 4)\n",
    "c = torch.rand(1, 2, 4)\n",
    "\n",
    "stackedTensor2 = torch.stack((a, b, c), dim = 0)\n",
    "stackedTensor3 = torch.stack((a, b, c), dim = 1)\n",
    "stackedTensor4 = torch.stack((a, b, c), dim = 2)\n",
    "stackedTensor5 = torch.stack((a, b, c), dim = 3)\n",
    "\n",
    "a, b, c, stackedTensor2, a.shape, stackedTensor2.shape, stackedTensor3.shape, stackedTensor4.shape, stackedTensor5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are n number of dimensions in the stacked tensors, we can use dim = from (-n) to (n-1)\n",
    "\n",
    "in the example, there are three 1 x 2 x 4 tensors.\n",
    "\n",
    "Using dim = 0 results in a tensor of three 1 x 2 x 4 tensors [on top of another & default]\n",
    "\n",
    "dim = 1 results in a tensor of one 3 x 2 x 4 tensors and so on...\n",
    "\n",
    "## HSTACK & VSTACK\n",
    "\n",
    "torch.hstack() -> stacks horizontally\n",
    "torch.vstack() -> stacks vertically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "         [3, 2, 1, 6, 5, 4, 9, 8, 7]]),\n",
       " tensor([[1, 2, 3],\n",
       "         [3, 2, 1],\n",
       "         [4, 5, 6],\n",
       "         [6, 5, 4],\n",
       "         [7, 8, 9],\n",
       "         [9, 8, 7]]))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3], [3,2,1]])\n",
    "y = torch.tensor([[4,5,6], [6,5,4]])\n",
    "z = torch.tensor([[7,8,9], [9,8,7]])\n",
    "\n",
    "torch.hstack((x, y, z)), torch.vstack((x, y, z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQUEEZE and UNSQUEEZE\n",
    "\n",
    "squeeze() and unsqueeze() are tensor operations used to remove or add dimensions of size 1 from tensors.\n",
    "\n",
    "Syntax: tensor.squeeze(dim=None)\n",
    "\n",
    "If dim is not specified, it removes all dimensions of size 1.\n",
    "If dim is specified, it only removes that specific dimension if its size is 1. If the size is not 1, it raises an error.\n",
    "\n",
    "For example, if input is of shape: \n",
    "(A×1×B×C×1×D) then the input.squeeze() will be of shape: \n",
    "(A×B×C×D).\n",
    "\n",
    "Syntax: tensor.unsqueeze(dim)\n",
    "\n",
    "The dim parameter is where the new size 1 dimension will be added. The index of dim can be negative (starting from the last dimension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[[0.3789],\n",
       "            [0.9864]]]],\n",
       " \n",
       " \n",
       " \n",
       "         [[[[0.8655],\n",
       "            [0.0681]]]],\n",
       " \n",
       " \n",
       " \n",
       "         [[[[0.1279],\n",
       "            [0.6471]]]]]),\n",
       " torch.Size([3, 1, 1, 2, 1]))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, 1, 1, 2, 1)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3789, 0.9864],\n",
       "         [0.8655, 0.0681],\n",
       "         [0.1279, 0.6471]]),\n",
       " tensor([[0.3789, 0.9864],\n",
       "         [0.8655, 0.0681],\n",
       "         [0.1279, 0.6471]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SqueezedX = x.squeeze()\n",
    "SqueezedX2 = torch.squeeze(x)\n",
    "SqueezedX, SqueezedX2, SqueezedX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8727, 0.9868, 0.5519, 0.9232, 0.0992, 0.2315, 0.6114]]),\n",
       " tensor([[[0.8727, 0.9868, 0.5519, 0.9232, 0.0992, 0.2315, 0.6114]]]),\n",
       " tensor([[[0.8727, 0.9868, 0.5519, 0.9232, 0.0992, 0.2315, 0.6114]]]),\n",
       " torch.Size([1, 1, 7]))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newX = torch.rand(1, 7)\n",
    "newUnSqueezedX = newX.unsqueeze(dim = 1)    #Adds a dimension at the specified index\n",
    "newUnSqueezedX2 = torch.unsqueeze(newX, dim = 1)\n",
    "newX, newUnSqueezedX, newUnSqueezedX2, newUnSqueezedX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns a view of the original tensor input with its dimensions permuted.\n",
    "\n",
    "Parameters\n",
    "input (Tensor) – the input tensor.\n",
    "\n",
    "dims (tuple of int) – The desired ordering of dimensions\n",
    "\n",
    "Since permute() returns a view, any change on the permutation will reflect on the actual tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2, 1]),\n",
       " tensor([[[0.2172],\n",
       "          [0.7482]],\n",
       " \n",
       "         [[0.9270],\n",
       "          [0.7055]],\n",
       " \n",
       "         [[0.1485],\n",
       "          [0.7263]]]),\n",
       " torch.Size([1, 3, 2]),\n",
       " tensor([[[0.2172, 0.7482],\n",
       "          [0.9270, 0.7055],\n",
       "          [0.1485, 0.7263]]]))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newT = torch.rand(3, 2, 1)\n",
    "\n",
    "permutedT = newT.permute(2, 0, 1)  #Shifts the 0th dimension to 2nd, 1st to 0th and 2nd to 1st\n",
    "newT.shape, newT, permutedT.shape, permutedT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Elements by Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxTensor = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "idxTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Access by Index\n",
    "idxTensor[0][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7, 8, 9]), tensor([1, 2, 3]), tensor([7, 8, 9]))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Access all values of a common dimension with \":\" operator\n",
    "idxTensor[0][2][:], idxTensor[0][:][0], idxTensor[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idxTensor[0][2][ : ] tries to select all values of idxTensor[0][2]\n",
    "\n",
    "idxTensor[0][ : ][0] tries to select all values of idxTensor[0], which is the whole 3x3 matrix. Then the last index [0] picks the first row from there, which is tensor([1, 2, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
