{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction To Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor is a mathematical object that generalizes scalars, vectors, and matrices to higher dimensions. In simple terms, a tensor is an n-dimensional array or a multi-dimensional matrix used to represent data in machine learning, deep learning, and scientific computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalar (0-D Tensor):\n",
    "\n",
    "A single number.\n",
    "Example: 5.0, 42, -3\n",
    "\n",
    "Vector (1-D Tensor):\n",
    "\n",
    "A one-dimensional array of numbers.\n",
    "Example: [1, 2, 3], [0.1, 0.2, 0.3]\n",
    "\n",
    "Matrix (2-D Tensor):\n",
    "\n",
    "A two-dimensional array (rows and columns).\n",
    "Example:\n",
    "[[1, 2],\n",
    "[3, 4]]\n",
    "\n",
    "Higher-dimensional Tensors (n-D Tensors):\n",
    "\n",
    "Tensors with 3 or more dimensions, used in deep learning and more complex data representations.\n",
    "Example (3D tensor): A batch of 2 images, each of 3x4 pixels with RGB channels\n",
    "\n",
    "[[[r1, g1, b1], [r2, g2, b2], [r3, g3, b3], [r4, g4, b4]],\n",
    " [[r5, g5, b5], [r6, g6, b6], [r7, g7, b7], [r8, g8, b8]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:275: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCALAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dimension of a scalar is 0*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 1, 3, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([4, 1, 3, 2])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "print(vector.ndim)\n",
    "print(vector.shape)\n",
    "print(vector.size())\n",
    "#Size and Shape are different version of the same thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 2],\n",
       "        [3, 3, 1],\n",
       "        [5, 3, 2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1, 3, 2], [3, 3, 1], [5, 3, 2]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "tensor([1, 3, 2])\n",
      "tensor([3, 3, 1])\n",
      "tensor([5, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(matrix.ndim)\n",
    "print(matrix.shape)\n",
    "print(matrix.size())\n",
    "for i in matrix:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "2\n",
      "torch.Size([3, 3])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(tensor)\n",
    "print(tensor.ndim)\n",
    "print(tensor.shape)\n",
    "print(tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "3\n",
      "torch.Size([1, 3, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "print(tensor)\n",
    "print(tensor.ndim)\n",
    "print(tensor.shape)\n",
    "print(tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1, 2, 3],\n",
      "          [4, 5, 6],\n",
      "          [7, 8, 9]]]])\n",
      "4\n",
      "torch.Size([1, 1, 3, 3])\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[[[1, 2, 3], [4, 5, 6], [7, 8, 9]]]])\n",
    "print(tensor)\n",
    "print(tensor.ndim)\n",
    "print(tensor.shape)\n",
    "print(tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1, 2, 3],\n",
      "          [4, 5, 6],\n",
      "          [7, 8, 9]],\n",
      "\n",
      "         [[1, 2, 3],\n",
      "          [4, 5, 6],\n",
      "          [7, 8, 9]]]])\n",
      "4\n",
      "torch.Size([1, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "longerTensor = torch.tensor([[[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]]])\n",
    "print(longerTensor)\n",
    "print(longerTensor.ndim)\n",
    "print(longerTensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Tensors in PyTorch\n",
    "\n",
    "In PyTorch, random tensors are tensors filled with random values.\n",
    "\n",
    "Practical Use Cases for Random Tensors\n",
    "\n",
    "Many neural networks learn by starting with full of random numbers and then adjust those random numbers to better represent the data\n",
    "\n",
    "Start with Random Numbers -> Look At Data -> Update Random Numbers -> Look At Data -> Update Random Numbers -> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4437, 0.6053, 0.1924, 0.7387],\n",
       "         [0.8984, 0.4453, 0.1067, 0.5444],\n",
       "         [0.1900, 0.4050, 0.8005, 0.4282]],\n",
       "\n",
       "        [[0.1551, 0.6791, 0.9705, 0.3677],\n",
       "         [0.8292, 0.9093, 0.2107, 0.8941],\n",
       "         [0.4052, 0.9145, 0.0562, 0.3174]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Random Tensor of size 2x3x4\n",
    "randomTensor = torch.rand(2, 3, 4)\n",
    "randomTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any Data can be written as Tensors.\n",
    "\n",
    "For example an image of 256x256 resolution will have a tensor of [3, 256, 256] size in RGB color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4788, 0.3380, 0.4646,  ..., 0.6585, 0.2157, 0.3523],\n",
       "         [0.1027, 0.4059, 0.7165,  ..., 0.9989, 0.2665, 0.2644],\n",
       "         [0.7088, 0.9397, 0.5347,  ..., 0.2180, 0.3394, 0.0371],\n",
       "         ...,\n",
       "         [0.9942, 0.5686, 0.5203,  ..., 0.4048, 0.0973, 0.2456],\n",
       "         [0.0654, 0.3632, 0.2024,  ..., 0.6251, 0.6417, 0.3014],\n",
       "         [0.0434, 0.9214, 0.7713,  ..., 0.6021, 0.8250, 0.3111]],\n",
       "\n",
       "        [[0.5297, 0.9274, 0.6935,  ..., 0.0456, 0.1575, 0.5116],\n",
       "         [0.3112, 0.1420, 0.2795,  ..., 0.1992, 0.7600, 0.9885],\n",
       "         [0.8220, 0.7118, 0.8123,  ..., 0.7935, 0.8633, 0.0341],\n",
       "         ...,\n",
       "         [0.3546, 0.3109, 0.3284,  ..., 0.1866, 0.9737, 0.3098],\n",
       "         [0.3009, 0.9579, 0.7969,  ..., 0.1078, 0.1470, 0.6075],\n",
       "         [0.4562, 0.0292, 0.5107,  ..., 0.1396, 0.6653, 0.5243]],\n",
       "\n",
       "        [[0.6899, 0.3423, 0.3573,  ..., 0.6974, 0.9042, 0.7648],\n",
       "         [0.5445, 0.0246, 0.2013,  ..., 0.2013, 0.4484, 0.8952],\n",
       "         [0.1486, 0.5638, 0.6403,  ..., 0.4623, 0.7634, 0.3806],\n",
       "         ...,\n",
       "         [0.9474, 0.6630, 0.5123,  ..., 0.4081, 0.6980, 0.9169],\n",
       "         [0.2180, 0.3515, 0.0051,  ..., 0.9973, 0.9208, 0.8058],\n",
       "         [0.5320, 0.1057, 0.4287,  ..., 0.4709, 0.7004, 0.8485]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomImgSizeTensor = torch.rand(size = (3, 256, 256))\n",
    "randomImgSizeTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor of all zeroes\n",
    "tensorOfZeroes = torch.zeros(3, 3)\n",
    "tensorOfZeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor of all ones\n",
    "tensorOfOnes = torch.ones(3, 3)\n",
    "tensorOfOnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors use 32-bit float as its default datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorOfOnes.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Range of Tensors and Tensors-like\n",
    "\n",
    "torch.arange(start, end, step) -> stores values from start to (end-1)\n",
    "\n",
    "Tensors-like -> Creates a new tensor of the same shape.\n",
    "\n",
    "torch.zeros_like(x)\n",
    "\n",
    "torch.ones_like(x)\n",
    "\n",
    "torch.rand_like(x)\n",
    "\n",
    "torch.randn_like(x)\n",
    "\n",
    "torch.full_like(x, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  2,  4,  6,  8, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneToTen = torch.arange(start = 0, end = 12, step = 2)\n",
    "# or oneToTen = torch.arange(0, 12, 2)\n",
    "oneToTen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creatinng tensors-like\n",
    "tenZeros = torch.zeros_like(oneToTen)\n",
    "tenZeros"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
